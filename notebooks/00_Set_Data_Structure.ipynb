{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify and set the filepath structure for the project data to work with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "\n",
    "# Optional: to suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introductionary examples for os library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate how os.getcwd(), os.path.join(), os.path.exists() work\n",
    "\n",
    "path = os.path.join(os.getcwd(),\"..\", \"data\")\n",
    "print(f\"The path {path} exists:\\n{os.path.exists(path)}\\n\") # returns True if the folder or file exists\n",
    "\n",
    "path = os.path.join(path, '_original', 'All_Beauty.jsonl.gz')\n",
    "print(f\"The path {path} exists:\\n{os.path.exists(path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate how os.path.pardir and os.path.abspath() work\n",
    "\n",
    "# get the relative path of the parent folder of the working directory\n",
    "path = os.path.join(os.getcwd(), os.pardir)\n",
    "print(path)\n",
    "\n",
    "# and return the absolute path of the parent directory\n",
    "path = os.path.abspath(path)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create project folder structure and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 131\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# Check if the structure within data folder is existing and create them otherwise:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ListItem \u001b[38;5;129;01min\u001b[39;00m lstSubfolders:\n\u001b[1;32m--> 131\u001b[0m     \u001b[43mVerifyOrMakePath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mListItem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# set variable for download of files and later unpacking\u001b[39;00m\n\u001b[0;32m    134\u001b[0m source \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_original\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 33\u001b[0m, in \u001b[0;36mVerifyOrMakePath\u001b[1;34m(WorkingDirectory, Subfolder)\u001b[0m\n\u001b[0;32m     30\u001b[0m FullPath \u001b[38;5;241m=\u001b[39m FullPath\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# converted to list of arguments for os.path.join() function\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Check if the structure within the working directory is existing:\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;241m*\u001b[39mFullPath)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m: \u001b[38;5;66;03m# the * converts the list to comma seperated string arguments\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# If not create the subfolder    \u001b[39;00m\n\u001b[0;32m     35\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;241m*\u001b[39mFullPath))\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1368\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1340\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tillj\\nf\\capstone\\Capstone-Project-Recommender-System\\.venv2\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2185\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2182\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2184\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2185\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2187\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2190\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tillj\\nf\\capstone\\Capstone-Project-Recommender-System\\.venv2\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2254\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2251\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[0;32m   2252\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[1;32m-> 2254\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2255\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m   2257\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.11.3\\Lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''___FUNCTIONS___\n",
    "=================='''\n",
    "\n",
    "def VerifyOrMakePath(WorkingDirectory, Subfolder):\n",
    "    '''\n",
    "    Checks if a subfolder exist and creates it if it does not. \n",
    "    Requires the os library to work.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    WorkingDirectory : str (e.g.: os.getcwd())\n",
    "    Subfolder : str OR List of str (e.g.: ['foo','bar'])\n",
    "    '''    \n",
    "    if len(Subfolder) < 1: # no subfolder to be created\n",
    "        return \n",
    "        \n",
    "    if type(Subfolder) is list:        \n",
    "        if len(Subfolder) < 2: # just one element\n",
    "            Subfolder = str(Subfolder[0]) # convert to string\n",
    "        else: # convert to string with \",\" as delimiter\n",
    "            Subfolder = \",\".join(Subfolder)\n",
    "\n",
    "    # remove all whitespaces in the strings\n",
    "    if WorkingDirectory.isspace():\n",
    "        WorkingDirectory.replace(\" \",\"\")\n",
    "    if Subfolder.isspace():\n",
    "        Subfolder.replace(\" \",\"\")\n",
    "\n",
    "    FullPath = \",\".join((WorkingDirectory, Subfolder)) # full path, comma separated without spaces\n",
    "    FullPath = FullPath.split(\",\") # converted to list of arguments for os.path.join() function\n",
    "\n",
    "    # Check if the structure within the working directory is existing:\n",
    "    if os.path.exists(os.path.join(*FullPath)) == False: # the * converts the list to comma seperated string arguments\n",
    "        # If not create the subfolder    \n",
    "        os.mkdir(os.path.join(*FullPath))\n",
    "\n",
    "\n",
    "def ExtractAndMoveUnzipped(Source, Destination, FileList=\"ALL\", FileEnding=\".gz\" ):\n",
    "    '''\n",
    "    Extract gz files from a source and move the extracted files to a destination. \n",
    "    Can be specified by FileList and FileEnding. Default will extract all gz files.\n",
    "    Requires the os, shutil and gzip libraries to work. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Source : str\n",
    "    Destination : str\n",
    "    FileList : list of strings\n",
    "    FileEnding : str\n",
    "    '''\n",
    "    \n",
    "    # check if unzip and shutil packages are installed:\n",
    "    pip_list = os.popen('pip list').read().strip() #pip list all installed packages and remove spaces\n",
    "    #print(f\"pip list: {pip_list}\")\n",
    "    Package = list(pip_list.split(\"\\n\")) #split by end of line\n",
    "    #print(f\"Package: {Package}\")\n",
    "\n",
    "    c = 0\n",
    "    for i in Package:\n",
    "        if \"gzip\" in i or \"shutil\" in i:\n",
    "            c = c + 1\n",
    "    \n",
    "    if c !=2:\n",
    "        print(\"Please verify that gzip and shutil libary are installed in your environment.\\nYou can try install them or extract and move the files manually as needed.\")\n",
    "        return\n",
    "    \n",
    "    if FileList == \"ALL\":\n",
    "        FileList = os.listdir(Source)\n",
    "\n",
    "    for filename in FileList:\n",
    "        if os.path.isfile(os.path.join(Source, filename)): \n",
    "            if filename.endswith(FileEnding):\n",
    "                # unzip downloaded files from _original into destination\n",
    "                with gzip.open(filename, 'rb') as f_in:\n",
    "                    with open(filename[:-3], 'wb') as f_out:\n",
    "                        shutil.copyfileobj(f_in, f_out)\n",
    "                        shutil.move(os.path.join(Source, f_out), Destination)\n",
    "                print(f\"File {filename} has been unzipped and the extracted file was moved to {Destination}\")\n",
    "        else:\n",
    "            print(\"Please verify the {filename} file exists in\\n{Source}\")\n",
    "\n",
    "\n",
    "def DownloadDataFiles(dctFilenameUrl, DownloadFolder):\n",
    "    '''Download data files from the internet provided in a dictionary to a specified folder. \n",
    "    The dictionary key is the filename and the value contains the download url.\n",
    "    Requires the os library to work.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dctFilenameUrl : dict (e.g.: {\"key1FileName\": 'value1Url', \"key2FileName\": 'value2Url'})\n",
    "    DownloadFolder : str (e.g.: os.getcwd())\n",
    "\n",
    "    '''\n",
    "    for filename, url in dctFilenameUrl.items():\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            with open(os.path.join(DownloadFolder, filename), 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\" File {filename} dowloaded sucessfully\")\n",
    "        else:\n",
    "            print(f\" Failed to download {filename}. \\nPlease download manually to {DownloadFolder}.\")\n",
    "\n",
    "\n",
    "\n",
    "'''___MAIN___\n",
    "================='''\n",
    "\n",
    "# Get the current notebook working directory (\"./notebooks\")  for the \"./../data\" folder and it's subolders to be created:\n",
    "path = os.path.join(os.getcwd(), os.pardir) # get the relative path of the parent folder of the working directory\n",
    "path = os.path.abspath(path) # and return the absolute path of the parent directory for the data folder\n",
    "path = os.path.join(path, 'data') # path variable for \"data\" folder within the local github project on your machine\n",
    "\n",
    "# define the folder structure to be created. Subfolders can be created by a list of strings\n",
    "lstSubfolders = [\n",
    "    \"_original\", \n",
    "    \"json_files\", \n",
    "    \"csv_transformed\", \n",
    "    \"data_clean\", \n",
    "    \"json_normalized\", \n",
    "    \"embeddings_output\",\n",
    "    \"embeddings_dim_reduction\",\n",
    "    \"text_analysis\",\n",
    "    [\"text_analysis\",\"user_vectors\"],\n",
    "    [\"text_analysis\",\"product_vectors\"],\n",
    "    \"cos_similarity\"\n",
    "    ]\n",
    "\n",
    "# Check if the structure within data folder is existing and create them otherwise:\n",
    "for ListItem in lstSubfolders:\n",
    "    VerifyOrMakePath(path, ListItem)\n",
    "\n",
    "# set variable for download of files and later unpacking\n",
    "source = os.path.join(path, '_original')\n",
    "\n",
    "# create a dictionary of files and their download urls:\n",
    "dctDownloads = {\n",
    "    \"All_Beauty.jsonl.gz\": 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/review_categories/All_Beauty.jsonl.gz',\n",
    "    \"meta_All_Beauty.jsonl.gz\": 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/meta_categories/meta_All_Beauty.jsonl.gz',\n",
    "    \"df_user_embeddings_BERT.csv.gz\": 'https://drive.google.com/file/d/1a_HQWlphn-wqm6MD5IDPTuzY_-Q7bw6A',\n",
    "    \"df_user_embeddings_BERT_merged.csv.gz\": 'https://drive.google.com/file/d/1szxv2o2GR-wIIPpgZowsHvE4hGtEJzQ2',\n",
    "    \"merged_user_meta_df.csv\": 'https://drive.google.com/file/d/1KUm8JMC8L5VrLVKNnJ7i9jDTQtXH85cQ'\n",
    "    }\n",
    "\n",
    "# download the data files to './data/_original' folder\n",
    "if os.path.exists(source):\n",
    "    DownloadDataFiles(dctDownloads, source)\n",
    "\n",
    "# extract the downloaded .gz files and move the unzipped files\n",
    "if os.path.exists(os.path.join(path, 'json_files')):\n",
    "    destination = os.path.join(path, 'json_files')\n",
    "    ExtractAndMoveUnzipped(source, destination, FileEnding= 'jsonl.gz')\n",
    "\n",
    "if os.path.exists(os.path.join(path, 'embeddings_output')):\n",
    "    destination = os.path.join(path, 'embeddings_output')\n",
    "    ExtractAndMoveUnzipped(source, destination, FileEnding= 'csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a flattend CSV from the downloaded JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the nested JSON datasets of the items descpritions and users ratings into flattend CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the relative path of the parent folder of the working directory\n",
    "# and return the absolute path of the parent directory for the data folder\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), os.pardir)) \n",
    "path = os.path.join(path, 'data') # path variable for \"data\" folder within the local github project on your machine\n",
    "\n",
    "if os.path.exists(os.path.join(path, 'json_normalized', 'normalized_user.csv')) == False:\n",
    "    # Flatten nested json file of 'user' data\n",
    "    json_file_user = os.path.join(path, \"json_files\", \"All_Beauty.jsonl\") #'.\\..\\data\\json_files\\All_Beauty.jsonl'\n",
    "    nested_data = []\n",
    "    with open(json_file_user, 'r') as file:\n",
    "        for line in file:\n",
    "            nested_data.append(json.loads(line))\n",
    "\n",
    "    df_user = json_normalize(nested_data)\n",
    "    df_user.to_csv(r'.\\..\\data\\json_normalized\\normalized_user.csv', index=False)\n",
    "    \n",
    "    print(\"Nested JSON file has been flattened and saved as \\n'.\\data\\json_normalized\\normalized_user.csv'.\")\n",
    "\n",
    "# \n",
    "elif os.path.exists(os.path.join(path, 'csv_transformed', 'meta.csv')) == False:\n",
    "    json_file_meta = os.path.join(path, \"json_files\", \"meta_All_Beauty.jsonl\") #'.\\..\\data\\json_files\\meta_All_Beauty.jsonl'\n",
    "    df_meta = pd.read_json(json_file_meta, lines=True)\n",
    "    # Specify the path for the CSV:\n",
    "    csv_meta = r'.\\..\\data\\csv_transformed\\meta.csv'\n",
    "    # Save the DataFrame as a CSV file\n",
    "    df_meta.to_csv(csv_meta, index=False)\n",
    "    \n",
    "    print(f\"JSON file has been converted to CSV and saved as '{csv_meta}'.\")\n",
    "\n",
    "else:\n",
    "    print(\"Most likely the corresponding folder structure and csv file already exists.\\nIn case it does not please repeat the previous steps or adapt the folder structure manually\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
