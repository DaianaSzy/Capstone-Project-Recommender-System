{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the data frame with BERT embeddings:\n",
    "file_path_embeddings = r'.\\..\\data\\embeddings_output\\df_user_embeddings_BERT_merged20241231_225046.csv' # Update this with your file path \n",
    "df_user_embeddings = pd.read_csv(file_path_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_title</th>\n",
       "      <th>text_review</th>\n",
       "      <th>user_images</th>\n",
       "      <th>product_ID</th>\n",
       "      <th>parent_ID</th>\n",
       "      <th>user_ID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_review_vote</th>\n",
       "      <th>user_purchase_verification</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_758</th>\n",
       "      <th>dim_759</th>\n",
       "      <th>dim_760</th>\n",
       "      <th>dim_761</th>\n",
       "      <th>dim_762</th>\n",
       "      <th>dim_763</th>\n",
       "      <th>dim_764</th>\n",
       "      <th>dim_765</th>\n",
       "      <th>dim_766</th>\n",
       "      <th>dim_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Such a lovely scent but not overpowering.</td>\n",
       "      <td>This spray is really nice. It smells really go...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00YQ6X8EO</td>\n",
       "      <td>B00YQ6X8EO</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>2020-05-05 14:08:48.923</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002711</td>\n",
       "      <td>-0.460343</td>\n",
       "      <td>0.018323</td>\n",
       "      <td>-0.174986</td>\n",
       "      <td>0.113852</td>\n",
       "      <td>0.096990</td>\n",
       "      <td>-0.149028</td>\n",
       "      <td>-0.278070</td>\n",
       "      <td>-0.180932</td>\n",
       "      <td>0.246443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Works great but smells a little weird.</td>\n",
       "      <td>This product does what I need it to do, I just...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B081TJ8YS3</td>\n",
       "      <td>B081TJ8YS3</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>2020-05-04 18:10:55.070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179098</td>\n",
       "      <td>-0.336104</td>\n",
       "      <td>0.016370</td>\n",
       "      <td>0.050976</td>\n",
       "      <td>0.144952</td>\n",
       "      <td>-0.161408</td>\n",
       "      <td>-0.334452</td>\n",
       "      <td>-0.221662</td>\n",
       "      <td>-0.220744</td>\n",
       "      <td>0.071765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                               review_title   \n",
       "0       5  Such a lovely scent but not overpowering.  \\\n",
       "1       4     Works great but smells a little weird.   \n",
       "\n",
       "                                         text_review user_images  product_ID   \n",
       "0  This spray is really nice. It smells really go...          []  B00YQ6X8EO  \\\n",
       "1  This product does what I need it to do, I just...          []  B081TJ8YS3   \n",
       "\n",
       "    parent_ID                       user_ID                timestamp   \n",
       "0  B00YQ6X8EO  AGKHLEW2SOWHNMFQIJGBECAF7INQ  2020-05-05 14:08:48.923  \\\n",
       "1  B081TJ8YS3  AGKHLEW2SOWHNMFQIJGBECAF7INQ  2020-05-04 18:10:55.070   \n",
       "\n",
       "   helpful_review_vote  user_purchase_verification  ...   dim_758   dim_759   \n",
       "0                    0                           1  ... -0.002711 -0.460343  \\\n",
       "1                    1                           1  ... -0.179098 -0.336104   \n",
       "\n",
       "    dim_760   dim_761   dim_762   dim_763   dim_764   dim_765   dim_766   \n",
       "0  0.018323 -0.174986  0.113852  0.096990 -0.149028 -0.278070 -0.180932  \\\n",
       "1  0.016370  0.050976  0.144952 -0.161408 -0.334452 -0.221662 -0.220744   \n",
       "\n",
       "    dim_767  \n",
       "0  0.246443  \n",
       "1  0.071765  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_embeddings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692331, 785)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Identify columns of interest (dim_0 to dim_767)\n",
    "columns_of_interest = [f'dim_{i}' for i in range(768)]\n",
    "\n",
    "# Count rows with NaN in these columns\n",
    "num_rows_with_nan = df_user_embeddings[columns_of_interest].isna().any(axis=1).sum()\n",
    "\n",
    "# Display the count\n",
    "print(num_rows_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693941, 14)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload user DataFrame:\n",
    "file_path_user_df = r'.\\..\\data\\data_clean\\merged_user_meta_df.csv'  # Update this with your file path\n",
    "df_user = pd.read_csv(file_path_user_df)\n",
    "df_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating                           0\n",
       "review_title                     0\n",
       "text_review                      0\n",
       "user_images                      0\n",
       "product_ID                       0\n",
       "parent_ID                        0\n",
       "user_ID                          0\n",
       "timestamp                        0\n",
       "helpful_review_vote              0\n",
       "user_purchase_verification       0\n",
       "year                             0\n",
       "cleaned_text                  1405\n",
       "parent_asin                      0\n",
       "cleaned_title                  205\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = df_user.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692331, 14)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.dropna(inplace=True)\n",
    "df_user.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Normalization of BERT embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.96 GiB for an array with shape (768, 692331) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m embedding_columns \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_user_embeddings\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Convert to NumPy array\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m embedding_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdf_user_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43membedding_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues  \n\u001b[0;32m      5\u001b[0m embedding_matrix\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:3773\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   3771\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(indexer)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 3773\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[0;32m   3776\u001b[0m     \u001b[38;5;66;03m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[0;32m   3777\u001b[0m     \u001b[38;5;66;03m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[0;32m   3778\u001b[0m     \u001b[38;5;66;03m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[0;32m   3779\u001b[0m     \u001b[38;5;66;03m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[0;32m   3780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[0;32m   3781\u001b[0m         \u001b[38;5;66;03m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3948\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   3941\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3942\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3943\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3946\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3948\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   3950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3932\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[1;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[0;32m   3924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3925\u001b[0m         axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3926\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m indices\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3927\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   3928\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(indices, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m   3929\u001b[0m     ):\n\u001b[0;32m   3930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 3932\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3934\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3937\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:963\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[0;32m    960\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    962\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 963\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:740\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 740\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    748\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    749\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    756\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:898\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    896\u001b[0m                     blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    897\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 898\u001b[0m                 nb \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmgr_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m                 blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:945\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m    942\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m    952\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    155\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.96 GiB for an array with shape (768, 692331) and data type float64"
     ]
    }
   ],
   "source": [
    "# Select only columns with embedding vectors (e.g., `dim_0`, `dim_1`, ..., `dim_780`)\n",
    "embedding_columns = [col for col in df_user_embeddings.columns if col.startswith('dim_')]\n",
    "# Convert to NumPy array\n",
    "embedding_matrix = df_user_embeddings[embedding_columns].values  \n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute L2 norm along rows\n",
    "l2_norms = np.linalg.norm(embedding_matrix, axis=1, keepdims=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01986643,  0.00568157,  0.05354686, ..., -0.03238795,\n",
       "        -0.02107394,  0.02870429],\n",
       "       [ 0.03096874,  0.02673078,  0.04876649, ..., -0.02550974,\n",
       "        -0.02540412,  0.00825897],\n",
       "       [ 0.01324259, -0.00577694,  0.07142085, ..., -0.03294062,\n",
       "        -0.05079956, -0.01763236],\n",
       "       ...,\n",
       "       [ 0.01123646, -0.02015455,  0.03780449, ..., -0.03049366,\n",
       "        -0.01812239, -0.01368994],\n",
       "       [ 0.00654949,  0.00044498,  0.05490762, ..., -0.03387531,\n",
       "         0.01581518, -0.01931256],\n",
       "       [-0.00473396,  0.00011211,  0.03517608, ..., -0.03265477,\n",
       "        -0.01554855,  0.03039072]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the embedding columns\n",
    "normalized_embeddings = embedding_matrix / l2_norms  # Divide each row by its L2 norm\n",
    "normalized_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the output DataFrame with normalized embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dimensions = normalized_embeddings.shape[1]\n",
    "norm_embedding_columns_names = [f'dim_norm_{i}' for i in range(num_dimensions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_norm = pd.DataFrame(normalized_embeddings, columns=norm_embedding_columns_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692331, 14)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.96 GiB for an array with shape (768, 692331) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_normalized_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_user\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings_norm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_normalized_embeddings\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:385\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    372\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    373\u001b[0m     objs,\n\u001b[0;32m    374\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    383\u001b[0m )\n\u001b[1;32m--> 385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    620\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:203\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# Assertions disabled for performance\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m#    indexers = tup[1]\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_concat_managers_axis0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m mgrs_indexers \u001b[38;5;241m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers)\n\u001b[0;32m    207\u001b[0m concat_plans \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    208\u001b[0m     _get_mgr_concatenation_plan(mgr, indexers) \u001b[38;5;28;01mfor\u001b[39;00m mgr, indexers \u001b[38;5;129;01min\u001b[39;00m mgrs_indexers\n\u001b[0;32m    209\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:278\u001b[0m, in \u001b[0;36m_concat_managers_axis0\u001b[1;34m(mgrs_indexers, axes, copy)\u001b[0m\n\u001b[0;32m    276\u001b[0m     nb \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy:\n\u001b[1;32m--> 278\u001b[0m     nb \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# by slicing instead of copy(deep=False), we get a new array\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m#  object, see test_concat_copy\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     nb \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mgetitem_block(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\Marcelina\\Documents\\neuefische\\github\\Capstone-Project-Recommender-System\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:540\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    538\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 540\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    541\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.96 GiB for an array with shape (768, 692331) and data type float64"
     ]
    }
   ],
   "source": [
    "df_normalized_embeddings = pd.concat([df_user.reset_index(drop=True), embeddings_norm], axis=1)\n",
    "df_normalized_embeddings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating            0\n",
       "review_title      0\n",
       "text_review       0\n",
       "user_images       0\n",
       "product_ID        0\n",
       "               ... \n",
       "dim_norm_763    205\n",
       "dim_norm_764    205\n",
       "dim_norm_765    205\n",
       "dim_norm_766    205\n",
       "dim_norm_767    205\n",
       "Length: 780, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = df_normalized_embeddings.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n"
     ]
    }
   ],
   "source": [
    "# Identify columns of interest (dim_0 to dim_767)\n",
    "columns_of_interest = [f'dim_norm_{i}' for i in range(768)]\n",
    "\n",
    "# Count rows with NaN in these columns\n",
    "num_rows_with_nan_norm = df_normalized_embeddings[columns_of_interest].isna().any(axis=1).sum()\n",
    "\n",
    "# Display the count\n",
    "print(num_rows_with_nan_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dimentionality reduction with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Similar steps but here the output is a final user dataframe with vectors of 300 dimensions (In the beginning I have chosen 10 only because that's what they have done in the artile but the variance dropped to 45%, so I set up for now 300 which gives ~95%.) We can always adjust it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 50)  # Adjust column width\n",
    "pd.set_option('display.width', 100)       # Adjust width of display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform dimensionality reduction to 300 components using PCA\n",
    "pca = PCA(n_components=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_embeddings = pca.fit_transform(normalized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(692331, 300)\n"
     ]
    }
   ],
   "source": [
    "print(pca_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.93043088e-01, -9.40082575e-05, -3.13472032e-02, ...,\n",
       "        -8.52035323e-04,  3.98247530e-03,  1.30807673e-02],\n",
       "       [-1.04640375e-01, -1.21517591e-02, -3.88902963e-02, ...,\n",
       "         1.11148856e-03, -7.79277755e-03,  1.70597137e-03],\n",
       "       [ 8.56322562e-02,  2.08808937e-01, -4.26144971e-02, ...,\n",
       "        -6.19684556e-03,  4.23237238e-03,  1.34907305e-02],\n",
       "       ...,\n",
       "       [ 1.97261689e-02,  2.71948796e-01,  7.76883388e-02, ...,\n",
       "        -1.23746901e-02, -8.61259473e-03,  7.21762474e-03],\n",
       "       [-5.53435766e-02, -2.48316794e-02,  2.53586109e-01, ...,\n",
       "        -1.57836610e-02, -4.27541505e-03,  2.83680449e-03],\n",
       "       [-1.86513871e-01, -3.51712366e-02, -4.08929099e-02, ...,\n",
       "        -4.18965602e-03, -1.07518770e-03, -2.52615804e-03]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. PCA - Variance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Verify if the size of reduced embeddings is big enough to still keep the meaning of the textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692331, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio for 300 Dimensions: [0.09388509 0.06763783 0.05461393 0.04048936 0.03222465 0.02656826\n",
      " 0.02530867 0.02390561 0.02212245 0.02004999 0.01728898 0.01607446\n",
      " 0.01496901 0.01451433 0.01337311 0.01198212 0.01150465 0.01016104\n",
      " 0.00972864 0.00959086 0.00907417 0.00862593 0.00843039 0.0080386\n",
      " 0.0078605  0.00746758 0.00727066 0.00710616 0.00694043 0.00666061\n",
      " 0.0062848  0.00609209 0.0057726  0.00557458 0.00550601 0.00524735\n",
      " 0.00503372 0.00495834 0.00489018 0.00459477 0.00455589 0.00445912\n",
      " 0.00426084 0.00419414 0.00413557 0.00410876 0.00378109 0.00371074\n",
      " 0.0036158  0.00358189 0.00345707 0.00339095 0.00333523 0.00324629\n",
      " 0.00319223 0.00313115 0.0030613  0.00295225 0.0029167  0.00284382\n",
      " 0.00278852 0.00276716 0.00272038 0.00267801 0.00258487 0.00254854\n",
      " 0.00249327 0.00244202 0.00242671 0.00239366 0.00237287 0.00229181\n",
      " 0.00228183 0.00225001 0.00219681 0.00214667 0.00212555 0.00209668\n",
      " 0.00206847 0.00205754 0.00199271 0.0019618  0.00195612 0.00191887\n",
      " 0.00188277 0.00187851 0.00183412 0.00179734 0.00178115 0.00176617\n",
      " 0.00173572 0.00167936 0.00167258 0.00165658 0.00164151 0.00162823\n",
      " 0.0015956  0.00157502 0.00156661 0.0015117  0.001492   0.00147736\n",
      " 0.0014545  0.00144736 0.00143218 0.00142032 0.00140338 0.00135594\n",
      " 0.00134042 0.00133017 0.00132259 0.00130576 0.00130102 0.00128103\n",
      " 0.00126586 0.00125266 0.00124111 0.00122949 0.00122231 0.00121201\n",
      " 0.00119588 0.00117167 0.00116067 0.00114393 0.00112887 0.00112644\n",
      " 0.00111456 0.00109819 0.00108989 0.00107388 0.00106922 0.00105037\n",
      " 0.00102781 0.00101555 0.0010108  0.00100581 0.00099303 0.00097404\n",
      " 0.00096733 0.0009549  0.00094696 0.0009277  0.00091936 0.00091098\n",
      " 0.00090264 0.00089421 0.00088642 0.00087083 0.00086653 0.00085504\n",
      " 0.00084696 0.00083564 0.00083251 0.00082197 0.00081238 0.00080847\n",
      " 0.00079963 0.00079317 0.00077982 0.00077042 0.00075676 0.00075495\n",
      " 0.00074453 0.00074021 0.00073912 0.00073453 0.00072145 0.00071336\n",
      " 0.00070264 0.00070112 0.00069497 0.0006859  0.00068098 0.00067302\n",
      " 0.00067161 0.00066418 0.00065496 0.0006507  0.00064175 0.00063897\n",
      " 0.00063442 0.00062813 0.00061943 0.00061577 0.00060828 0.00060558\n",
      " 0.00059939 0.00059269 0.00058722 0.00058186 0.00058086 0.00057587\n",
      " 0.00057087 0.00056198 0.00056167 0.00055585 0.00055195 0.00054717\n",
      " 0.00054209 0.00053707 0.00053224 0.00052948 0.00051773 0.00051461\n",
      " 0.00051325 0.00050655 0.0005054  0.00050254 0.00049279 0.00048936\n",
      " 0.00048816 0.00048273 0.00048119 0.00047706 0.0004724  0.00046469\n",
      " 0.00046189 0.00046089 0.00045763 0.00044983 0.00044805 0.00044003\n",
      " 0.0004377  0.00043543 0.00043273 0.00042734 0.00042648 0.00042399\n",
      " 0.00041694 0.00041385 0.00041091 0.00040804 0.00040578 0.00040236\n",
      " 0.00039726 0.00039465 0.0003903  0.00038857 0.00038605 0.00038568\n",
      " 0.00038276 0.00037903 0.00037846 0.00037355 0.0003707  0.00036966\n",
      " 0.00036759 0.00036456 0.00036086 0.00035848 0.00035759 0.00035157\n",
      " 0.00035028 0.00034794 0.00034297 0.00034056 0.0003392  0.00033731\n",
      " 0.00033522 0.0003339  0.00033006 0.00032906 0.00032696 0.00032505\n",
      " 0.00032276 0.0003191  0.00031622 0.00031508 0.00031422 0.0003114\n",
      " 0.00030707 0.00030379 0.0003023  0.00030114 0.00029562 0.000293\n",
      " 0.00029215 0.0002906  0.00028799 0.00028625 0.00028458 0.00028104\n",
      " 0.00027904 0.00027868 0.00027564 0.00027291 0.00026885 0.0002655\n",
      " 0.000264   0.00026229 0.00026004 0.00025773 0.00025594 0.00025367\n",
      " 0.00025215 0.00025136 0.00024688 0.00024432 0.00024394 0.00023881]\n",
      "Total Explained Variance Captured by 300 Dimensions: 0.9496049591345089\n"
     ]
    }
   ],
   "source": [
    "# Fit PCA to the original embeddings\n",
    "pca = PCA(n_components=300)\n",
    "pca.fit(embeddings_norm)\n",
    "\n",
    "# Check explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "total_variance = sum(explained_variance)\n",
    "\n",
    "print(\"Explained Variance Ratio for 300 Dimensions:\", explained_variance)\n",
    "print(\"Total Explained Variance Captured by 300 Dimensions:\", total_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate a merged DataFrame from df_user, including columns for embedding dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column names for embedding dimensions - normalized data after dimentionality reducion\n",
    "num_dimensions_pca = pca_embeddings.shape[1]\n",
    "normalized_columns_PCA = [f'dim_norm_PCA{i}' for i in range(num_dimensions_pca)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df_PCA = pd.DataFrame(pca_embeddings, columns=normalized_columns_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_normalized_PCA = pd.concat([df_user.reset_index(drop=True), embeddings_df_PCA], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_title</th>\n",
       "      <th>text_review</th>\n",
       "      <th>user_images</th>\n",
       "      <th>product_ID</th>\n",
       "      <th>parent_ID</th>\n",
       "      <th>user_ID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_review_vote</th>\n",
       "      <th>user_purchase_verification</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_norm_PCA290</th>\n",
       "      <th>dim_norm_PCA291</th>\n",
       "      <th>dim_norm_PCA292</th>\n",
       "      <th>dim_norm_PCA293</th>\n",
       "      <th>dim_norm_PCA294</th>\n",
       "      <th>dim_norm_PCA295</th>\n",
       "      <th>dim_norm_PCA296</th>\n",
       "      <th>dim_norm_PCA297</th>\n",
       "      <th>dim_norm_PCA298</th>\n",
       "      <th>dim_norm_PCA299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Such a lovely scent but not overpowering.</td>\n",
       "      <td>This spray is really nice. It smells really go...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00YQ6X8EO</td>\n",
       "      <td>B00YQ6X8EO</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>2020-05-05 14:08:48.923</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.007982</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.013081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Works great but smells a little weird.</td>\n",
       "      <td>This product does what I need it to do, I just...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B081TJ8YS3</td>\n",
       "      <td>B081TJ8YS3</td>\n",
       "      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n",
       "      <td>2020-05-04 18:10:55.070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>-0.004751</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>-0.002100</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>-0.007793</td>\n",
       "      <td>0.001706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Yes!</td>\n",
       "      <td>Smells good, feels great!</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07PNNCSP9</td>\n",
       "      <td>B097R46CSY</td>\n",
       "      <td>AE74DYR3QUGVPZJ3P7RFWBGIX7XQ</td>\n",
       "      <td>2020-05-16 21:41:06.052</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007523</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.015971</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>-0.006197</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.013491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Synthetic feeling</td>\n",
       "      <td>Felt synthetic</td>\n",
       "      <td>[]</td>\n",
       "      <td>B09JS339BZ</td>\n",
       "      <td>B09JS339BZ</td>\n",
       "      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n",
       "      <td>2022-01-28 18:13:50.220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014391</td>\n",
       "      <td>-0.011825</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>-0.009527</td>\n",
       "      <td>-0.009967</td>\n",
       "      <td>0.012262</td>\n",
       "      <td>-0.005349</td>\n",
       "      <td>-0.006884</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.002718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A+</td>\n",
       "      <td>Love it</td>\n",
       "      <td>[]</td>\n",
       "      <td>B08BZ63GMJ</td>\n",
       "      <td>B08BZ63GMJ</td>\n",
       "      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n",
       "      <td>2020-12-30 10:02:43.534</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001701</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>-0.009939</td>\n",
       "      <td>0.009239</td>\n",
       "      <td>-0.008657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                               review_title   \n",
       "0       5  Such a lovely scent but not overpowering.  \\\n",
       "1       4     Works great but smells a little weird.   \n",
       "2       5                                       Yes!   \n",
       "3       1                          Synthetic feeling   \n",
       "4       5                                         A+   \n",
       "\n",
       "                                         text_review user_images  product_ID   parent_ID   \n",
       "0  This spray is really nice. It smells really go...          []  B00YQ6X8EO  B00YQ6X8EO  \\\n",
       "1  This product does what I need it to do, I just...          []  B081TJ8YS3  B081TJ8YS3   \n",
       "2                          Smells good, feels great!          []  B07PNNCSP9  B097R46CSY   \n",
       "3                                     Felt synthetic          []  B09JS339BZ  B09JS339BZ   \n",
       "4                                            Love it          []  B08BZ63GMJ  B08BZ63GMJ   \n",
       "\n",
       "                        user_ID                timestamp  helpful_review_vote   \n",
       "0  AGKHLEW2SOWHNMFQIJGBECAF7INQ  2020-05-05 14:08:48.923                    0  \\\n",
       "1  AGKHLEW2SOWHNMFQIJGBECAF7INQ  2020-05-04 18:10:55.070                    1   \n",
       "2  AE74DYR3QUGVPZJ3P7RFWBGIX7XQ  2020-05-16 21:41:06.052                    2   \n",
       "3  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ  2022-01-28 18:13:50.220                    0   \n",
       "4  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ  2020-12-30 10:02:43.534                    0   \n",
       "\n",
       "   user_purchase_verification  ...  dim_norm_PCA290 dim_norm_PCA291  dim_norm_PCA292   \n",
       "0                           1  ...         0.015361       -0.001200        -0.000402  \\\n",
       "1                           1  ...         0.006355       -0.004751         0.008120   \n",
       "2                           1  ...        -0.007523        0.003291         0.015971   \n",
       "3                           1  ...        -0.014391       -0.011825         0.003520   \n",
       "4                           1  ...        -0.001701        0.001943         0.003965   \n",
       "\n",
       "   dim_norm_PCA293  dim_norm_PCA294  dim_norm_PCA295  dim_norm_PCA296  dim_norm_PCA297   \n",
       "0         0.000824         0.007982         0.009948         0.000767        -0.000852  \\\n",
       "1        -0.002100         0.004687         0.007715         0.004464         0.001111   \n",
       "2         0.004241        -0.000083         0.003928         0.007203        -0.006197   \n",
       "3        -0.009527        -0.009967         0.012262        -0.005349        -0.006884   \n",
       "4         0.002679         0.001065         0.002341         0.005209        -0.009939   \n",
       "\n",
       "   dim_norm_PCA298  dim_norm_PCA299  \n",
       "0         0.003982         0.013081  \n",
       "1        -0.007793         0.001706  \n",
       "2         0.004232         0.013491  \n",
       "3         0.004388         0.002718  \n",
       "4         0.009239        -0.008657  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_normalized_PCA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n"
     ]
    }
   ],
   "source": [
    "# Identify columns of interest (dim_0 to dim_767)\n",
    "columns_of_interest_PCA = [f'dim_norm_PCA{i}' for i in range(294)]\n",
    "\n",
    "# Count rows with NaN in these columns\n",
    "num_rows_with_nan_norm_PCA = df_user_normalized_PCA[columns_of_interest_PCA].isna().any(axis=1).sum()\n",
    "\n",
    "# Display the count\n",
    "print(num_rows_with_nan_norm_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the output DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with normalized & reduced embeddings:\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "file_path = rf'.\\..\\data\\embeddings_dim_reduction\\df_user_normalized_PCA_merged{timestamp}.csv'\n",
    "df_user_normalized_PCA.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
